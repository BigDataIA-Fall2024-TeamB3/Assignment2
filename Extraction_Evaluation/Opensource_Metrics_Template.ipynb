{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f82643",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ca17c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pdfplumber\n",
    "from google.cloud import storage\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import fitz  # PyMuPDF for more efficient image extraction\n",
    "from dotenv import load_dotenv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5d23c0",
   "metadata": {},
   "source": [
    "## Load Environment Variables and Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3335516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set up logging for error tracking\n",
    "logging.basicConfig(filename='errors.log', level=logging.ERROR)\n",
    "\n",
    "# Set the GCP credentials and Tesseract path from .env\n",
    "gcp_key_file = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "tesseract_cmd_path = os.getenv(\"TESSERACT_CMD_PATH\")\n",
    "bucket_name = os.getenv(\"GCP_BUCKET_NAME\")\n",
    "source_folder = os.getenv(\"SOURCE_FOLDER\")\n",
    "target_folder = os.getenv(\"TARGET_FOLDER\")\n",
    "\n",
    "# Set the path to the GCP credentials\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = gcp_key_file\n",
    "\n",
    "# Initialize GCP storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Initialize Tesseract OCR\n",
    "pytesseract.pytesseract.tesseract_cmd = tesseract_cmd_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732ac91e",
   "metadata": {},
   "source": [
    "## Metrics Tracking Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "567c1d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics tracking variables\n",
    "total_files_processed = 0  # Tracks the number of PDF files processed\n",
    "total_pages_processed = 0  # Tracks the total number of pages processed across all files\n",
    "total_errors = 0  # Tracks the number of errors encountered during processing\n",
    "start_time = time.time()  # Records the start time for calculating total processing time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7caa2aa1",
   "metadata": {},
   "source": [
    "## Define Preprocessing and Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62bcbc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"Preprocess image to improve OCR results.\"\"\"\n",
    "    img = np.array(image)\n",
    "    if len(img.shape) == 2:\n",
    "        gray = img\n",
    "    elif len(img.shape) == 3 and img.shape[2] == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    elif len(img.shape) == 4:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGBA2GRAY)\n",
    "    else:\n",
    "        logging.error(f\"Unsupported image format: {img.shape}\")\n",
    "        return None\n",
    "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    return thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57351fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_table(table):\n",
    "    \"\"\"Formats the extracted table rows into structured, aligned output.\"\"\"\n",
    "    formatted_table = \"\"\n",
    "    max_lengths = [max(len(str(cell)) if cell else 0 for cell in col) for col in zip(*table)]\n",
    "    for row in table:\n",
    "        formatted_row = \" | \".join([str(cell).ljust(max_len) if cell else ''.ljust(max_len) for cell, max_len in zip(row, max_lengths)])\n",
    "        formatted_table += formatted_row + \"\\n\"\n",
    "    return formatted_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0e4e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_tables(pdf_data):\n",
    "    \"\"\"Extracts text and tables from the PDF using pdfplumber.\"\"\"\n",
    "    extracted_text = \"\"\n",
    "    structured_data = []\n",
    "    try:\n",
    "        with pdfplumber.open(io.BytesIO(pdf_data)) as pdf:\n",
    "            global total_pages_processed\n",
    "            total_pages_processed += len(pdf.pages)  # Increment page count\n",
    "            for page_num, page in enumerate(pdf.pages, 1):\n",
    "                tables = page.extract_tables()\n",
    "                if tables:\n",
    "                    for table in tables:\n",
    "                        formatted_table = format_table(table)\n",
    "                        structured_data.append({\n",
    "                            \"page_number\": page_num,\n",
    "                            \"tables\": formatted_table\n",
    "                        })\n",
    "                else:\n",
    "                    extracted_text += f\"Page {page_num} Text:\\n\"\n",
    "                    extracted_text += page.extract_text() or \"\"\n",
    "        return extracted_text, structured_data\n",
    "    except Exception as e:\n",
    "        global total_errors\n",
    "        total_errors += 1  # Increment error count\n",
    "        logging.error(f\"Error extracting text and tables: {e}\")\n",
    "        return \"\", []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2748364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_and_apply_ocr(pdf_data):\n",
    "    \"\"\"Extracts images from PDF using PyMuPDF (fitz) and applies OCR to extract text.\"\"\"\n",
    "    image_text = \"\"\n",
    "    try:\n",
    "        doc = fitz.open(stream=pdf_data, filetype=\"pdf\")\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            image_list = page.get_images(full=True)\n",
    "            for img_index, img in enumerate(image_list):\n",
    "                try:\n",
    "                    xref = img[0]\n",
    "                    base_image = doc.extract_image(xref)\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "                    img = Image.open(io.BytesIO(image_bytes))\n",
    "                    preprocessed_img = preprocess_image(img)\n",
    "                    if preprocessed_img is not None:\n",
    "                        extracted_image_text = pytesseract.image_to_string(preprocessed_img, config=\"--psm 6\")\n",
    "                        image_text += f\"\\n\\nPage {page_num + 1}, Image {img_index + 1} OCR Text:\\n{extracted_image_text}\"\n",
    "                    else:\n",
    "                        logging.error(f\"Skipping image on page {page_num + 1}, image {img_index + 1} due to processing error\")\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error extracting image on page {page_num + 1}, image {img_index + 1}: {e}\")\n",
    "        return image_text\n",
    "    except Exception as e:\n",
    "        global total_errors\n",
    "        total_errors += 1  # Increment error count\n",
    "        logging.error(f\"Error extracting images and applying OCR: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c22de3",
   "metadata": {},
   "source": [
    "## PDF Data Extraction and Saving Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57e8def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_data_from_gcp(bucket_name, folder_name, file_name):\n",
    "    \"\"\"Extracts text, tables, and images (with OCR) from a PDF stored in GCP.\"\"\"\n",
    "    global total_files_processed\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(f\"{folder_name}/{file_name}\")\n",
    "    \n",
    "    try:\n",
    "        pdf_data = blob.download_as_bytes()\n",
    "        total_files_processed += 1  # Increment file counter\n",
    "        extracted_text, structured_data = extract_text_and_tables(pdf_data)\n",
    "        image_text = extract_images_and_apply_ocr(pdf_data)\n",
    "        full_extracted_content = extracted_text + \"\\n\\nExtracted Text from Images:\\n\" + image_text\n",
    "        for table_data in structured_data:\n",
    "            full_extracted_content += f\"\\n\\nPage {table_data['page_number']} Tables:\\n\"\n",
    "            full_extracted_content += table_data['tables']\n",
    "        return full_extracted_content\n",
    "    except Exception as e:\n",
    "        global total_errors\n",
    "        total_errors += 1  # Increment error count\n",
    "        logging.error(f\"Error extracting PDF data from GCP: {e}\")\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b24a1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_extracted_data_to_gcp(bucket_name, folder_name, file_name, extracted_content):\n",
    "    \"\"\"Saves the extracted content as a .txt file to the specified GCP bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    txt_file_name = file_name.replace('.pdf', '.txt')\n",
    "    blob = bucket.blob(f\"{folder_name}/{txt_file_name}\")\n",
    "    blob.upload_from_string(extracted_content, content_type='text/plain')\n",
    "    print(f\"Extracted data saved to: {folder_name}/{txt_file_name} in bucket {bucket_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a4c79e",
   "metadata": {},
   "source": [
    " ## Processing PDFs and Tracking Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72fbd7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdfs_in_gcp(bucket_name, source_folder, target_folder):\n",
    "    \"\"\"Processes all PDFs in the source folder of GCP bucket and stores extracted data in the target folder.\"\"\"\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=f\"{source_folder}/\")\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith('.pdf'):\n",
    "            file_name = os.path.basename(blob.name)\n",
    "            print(f\"Processing file: {file_name}\")\n",
    "            extracted_content = extract_pdf_data_from_gcp(bucket_name, source_folder, file_name)\n",
    "            save_extracted_data_to_gcp(bucket_name, target_folder, file_name, extracted_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b351e32d",
   "metadata": {},
   "source": [
    "## Calculating Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dd58c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_metrics():\n",
    "    \"\"\"Calculates and prints performance metrics.\"\"\"\n",
    "    end_time = time.time()  # Capture the end time\n",
    "    total_time = end_time - start_time  # Calculate total time spent processing\n",
    "    latency = total_time / total_files_processed if total_files_processed > 0 else 0  # Average time per file\n",
    "    throughput = total_pages_processed / total_time if total_time > 0 else 0  # Pages processed per second\n",
    "    error_rate = total_errors / total_files_processed if total_files_processed > 0 else 0  # Percentage of files with errors\n",
    "    \n",
    "    print(f\"Total files processed: {total_files_processed}\")\n",
    "    print(f\"Total pages processed: {total_pages_processed}\")\n",
    "    print(f\"Total errors: {total_errors}\")\n",
    "    print(f\"Total time: {total_time:.2f} seconds\")\n",
    "    print(f\"Latency: {latency:.2f} seconds per file\")\n",
    "    print(f\"Throughput: {throughput:.2f} pages per second\")\n",
    "    print(f\"Error rate: {error_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78239791",
   "metadata": {},
   "source": [
    "## Run Processing and Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f08b521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: 021a5339-744f-42b7-bd9b-9368b3efda7a.pdf\n",
      "Extracted data saved to: opensource_extracted/021a5339-744f-42b7-bd9b-9368b3efda7a.txt in bucket gaia_files_pdf\n",
      "Processing file: 32f386b9-73ee-4455-b412-ddad508aa979.pdf\n",
      "Extracted data saved to: opensource_extracted/32f386b9-73ee-4455-b412-ddad508aa979.txt in bucket gaia_files_pdf\n",
      "Processing file: 366e2f2b-8632-4ef2-81eb-bc3877489217.pdf\n",
      "Extracted data saved to: opensource_extracted/366e2f2b-8632-4ef2-81eb-bc3877489217.txt in bucket gaia_files_pdf\n",
      "Processing file: 4044eab7-1282-42bd-a559-3bf3a4d5858e.pdf\n",
      "Extracted data saved to: opensource_extracted/4044eab7-1282-42bd-a559-3bf3a4d5858e.txt in bucket gaia_files_pdf\n",
      "Processing file: 634fca59-03b2-4cdf-9ce4-0205df22f256.pdf\n",
      "Extracted data saved to: opensource_extracted/634fca59-03b2-4cdf-9ce4-0205df22f256.txt in bucket gaia_files_pdf\n",
      "Processing file: 67e8878b-5cef-4375-804e-e6291fdbe78a.pdf\n",
      "Extracted data saved to: opensource_extracted/67e8878b-5cef-4375-804e-e6291fdbe78a.txt in bucket gaia_files_pdf\n",
      "Processing file: 680d7d77-c0c7-49c8-88fd-f8ec623645e9.pdf\n",
      "Extracted data saved to: opensource_extracted/680d7d77-c0c7-49c8-88fd-f8ec623645e9.txt in bucket gaia_files_pdf\n",
      "Processing file: 7c215d46-91c7-424e-9f22-37d43ab73ea6.pdf\n",
      "Extracted data saved to: opensource_extracted/7c215d46-91c7-424e-9f22-37d43ab73ea6.txt in bucket gaia_files_pdf\n",
      "Processing file: 8f697523-6988-4c4f-8d72-760a45681f68.pdf\n",
      "Extracted data saved to: opensource_extracted/8f697523-6988-4c4f-8d72-760a45681f68.txt in bucket gaia_files_pdf\n",
      "Processing file: b3654e47-4307-442c-a09c-945b33b913c6.pdf\n",
      "Extracted data saved to: opensource_extracted/b3654e47-4307-442c-a09c-945b33b913c6.txt in bucket gaia_files_pdf\n",
      "Processing file: be353748-74eb-4904-8f17-f180ce087f1a.pdf\n",
      "Extracted data saved to: opensource_extracted/be353748-74eb-4904-8f17-f180ce087f1a.txt in bucket gaia_files_pdf\n",
      "Processing file: c4456885-2f03-436f-8fe9-0b4ca6822cdb.pdf\n",
      "Extracted data saved to: opensource_extracted/c4456885-2f03-436f-8fe9-0b4ca6822cdb.txt in bucket gaia_files_pdf\n",
      "Processing file: e9a2c537-8232-4c3f-85b0-b52de6bcba99.pdf\n",
      "Extracted data saved to: opensource_extracted/e9a2c537-8232-4c3f-85b0-b52de6bcba99.txt in bucket gaia_files_pdf\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'gaia_files_pdf'\n",
    "source_folder = 'gaia_pdfs'\n",
    "target_folder = 'opensource_extracted'\n",
    "\n",
    "# Run the processing pipeline for all PDFs in the source folder\n",
    "process_pdfs_in_gcp(bucket_name, source_folder, target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66f20717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files processed: 13\n",
      "Total pages processed: 210\n",
      "Total errors: 0\n",
      "Total time: 56.85 seconds\n",
      "Latency: 4.37 seconds per file\n",
      "Throughput: 3.69 pages per second\n",
      "Error rate: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Calculate and display performance metrics\n",
    "calculate_performance_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfa668b",
   "metadata": {},
   "source": [
    "Explanation of Metrics:\n",
    "Latency: Average time (in seconds) to process each file. Calculated as total_time / total_files_processed.\n",
    "Throughput: The number of pages processed per second. Calculated as total_pages_processed / total_time.\n",
    "Error Rate: The percentage of files that encountered errors during processing. Calculated as total_errors / total_files_processed.\n",
    "Total Time: The overall time taken to process all files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
